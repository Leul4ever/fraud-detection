# ğŸ›¡ï¸ Fraud Detection for E-commerce & Banking ğŸ’³

[![Python 3.13](https://img.shields.io/badge/python-3.13-blue.svg)](https://www.python.org/downloads/release/python-3130/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![CI/CD](https://github.com/Leul4ever/fraud-detection/workflows/Unit%20Tests/badge.svg)](https://github.com/Leul4ever/fraud-detection/actions)

## ğŸ’¡ Project Idea

In the rapidly evolving digital landscape, fraudulent transactions pose a significant threat to financial security and user trust. This project aims to build a robust **Fraud Detection System** that analyzes transaction patterns in e-commerce and banking data to identify and prevent malicious activities.

## ğŸš€ Project Context

This project is part of a comprehensive data science workflow aimed at:
1. **Detecting patterns** associated with fraudulent activities.
2. **Bridging geolocation data** with transaction logs.
3. **Handling class imbalance** (since fraud cases are rare).
4. **Developing real-time detection** APIs and interactive dashboards.

## ğŸ“ Project Structure

Following the project requirements, the repository is organized as follows:

```
fraud-detection/
â”œâ”€â”€ .vscode/
â”‚   â””â”€â”€ settings.json             # Workspace settings
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ unittests.yml         # CI/CD pipeline
â”œâ”€â”€ data/                         # Project datasets (ignored except documentation)
â”‚   â”œâ”€â”€ raw/                      # Original, immutable datasets
â”‚   â””â”€â”€ processed/                # Cleaned and feature-engineered data
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ eda-fraud-data.ipynb       # EDA for e-commerce data
â”‚   â”œâ”€â”€ eda-creditcard.ipynb       # EDA for bank credit data
â”‚   â”œâ”€â”€ feature-engineering.ipynb  # Feature engineering logic
â”‚   â”œâ”€â”€ modeling.ipynb              # Model building and evaluation
â”‚   â”œâ”€â”€ shap-explainability.ipynb  # Model interpretability
â”‚   â””â”€â”€ README.md                  # Notebooks documentation
â”œâ”€â”€ src/                          # Core production modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_cleaning.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â””â”€â”€ model_training.py
â”œâ”€â”€ tests/                        # Automated unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/                       # Saved model artifacts (.pkl files)
â”œâ”€â”€ scripts/                      # Runner scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ requirements.txt              # Project dependencies
â”œâ”€â”€ README.md                     # Main documentation
â””â”€â”€ .gitignore                    # Git ignore rules
```

## ğŸ› ï¸ Installation & Setup

### Prerequisites
- Python 3.9+ (tested with Python 3.13)
- Git

### Setup Instructions

1. **Clone the Repository:**
   ```bash
   git clone https://github.com/Leul4ever/fraud-detection.git
   cd fraud-detection
   ```

2. **Create and Activate Virtual Environment:**
   ```bash
   python -m venv venv
   
   # Windows
   .\venv\Scripts\activate
   
   # Linux/Mac
   source venv/bin/activate
   ```

3. **Install Dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Run Data Pipeline:**
   ```bash
   python scripts/run_data_pipeline.py
   ```

5. **Run Tests:**
   ```bash
   pytest tests/ -v
   ```

## ğŸ“ˆ Roadmap (Tasks)

### âœ… Task 1: Data Preprocessing & EDA (Completed)
- **Data Cleaning**: Missing values, duplicates, and type corrections.
- **EDA**: Univariate/Bivariate analysis and class distribution.
- **Geolocation**: Mapping IP addresses to countries.
- **Feature Engineering**: Frequency, velocity, and time-based features.
- **Transformation**: Scaling and SMOTE for imbalance handling.

### âœ… Task 2: Model Building & Training (Completed)
- **Baseline**: Logistic Regression (AUC-PR, F1-Score).
- **Ensemble**: Random Forest & Tuned XGBoost.
- **Stability**: 5-fold Stratified Cross-Validation.
- **Selection**: XGBoost chosen for production based on AUC-PR.

### ğŸ“‹ Task 3: Model Explainability (Planned)
- SHAP global and local feature importance.

### ğŸš€ Task 4: Model Deployment (Planned)
- REST API serving with Flask/FastAPI.

### ğŸ“Š Task 5: Interactive Dashboard (Planned)
- Monitoring dashboard with Streamlit/Dash.

## ğŸ§° Tech Stack
- **Data**: Pandas, NumPy
- **ML**: Scikit-learn, XGBoost, Imbalanced-learn
- **Viz**: Matplotlib, Seaborn
- **Testing**: Pytest & GitHub Actions

## ğŸ¤ Contributing
Part of the **Kifiya AI Mentorship Program**.

## ğŸ“„ License
MIT License

## ğŸ‘¤ Author
**Leul** - [GitHub](https://github.com/Leul4ever)

---
**Last Updated:** Task 2 Completed âœ…  
**Next Milestone:** Task 3 - Model Explainability
