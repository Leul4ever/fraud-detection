{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "7f8b9e4a",
            "metadata": {},
            "source": [
                "# Feature Engineering\n",
                "This notebook documents the feature engineering process for the Fraud Detection project, focusing on the E-commerce dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d1c2b3a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import os\n",
                "\n",
                "# Load cleaned data\n",
                "fraud_df = pd.read_csv('../data/processed/Fraud_Data_cleaned.csv')\n",
                "ip_df = pd.read_csv('../data/raw/IpAddress_to_Country.csv')\n",
                "\n",
                "print(f\"Fraud Data Shape: {fraud_df.shape}\")\n",
                "print(f\"IP Mapping Shape: {ip_df.shape}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bbaa5b2a",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "id": "e5f6g7h8",
            "metadata": {},
            "source": [
                "## 1. Geolocation Integration\n",
                "Mapping IP addresses to countries using range-based lookup."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "i9j0k1l2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert IP to int64 for range matching\n",
                "fraud_df['ip_address'] = fraud_df['ip_address'].astype(np.int64)\n",
                "ip_df['lower_bound_ip_address'] = ip_df['lower_bound_ip_address'].astype(np.int64)\n",
                "ip_df['upper_bound_ip_address'] = ip_df['upper_bound_ip_address'].astype(np.int64)\n",
                "\n",
                "# Sort for merge_asof\n",
                "fraud_df = fraud_df.sort_values('ip_address')\n",
                "ip_df = ip_df.sort_values('lower_bound_ip_address')\n",
                "\n",
                "# Merging using asof (matches where ip_address >= lower_bound)\n",
                "df_merged = pd.merge_asof(\n",
                "    fraud_df, \n",
                "    ip_df, \n",
                "    left_on='ip_address', \n",
                "    right_on='lower_bound_ip_address'\n",
                ")\n",
                "\n",
                "# Validate upper bound\n",
                "df_merged['country'] = np.where(\n",
                "    df_merged['ip_address'] <= df_merged['upper_bound_ip_address'],\n",
                "    df_merged['country'],\n",
                "    'Unknown'\n",
                ")\n",
                "\n",
                "# Drop intermediate artifacts\n",
                "df_merged = df_merged.drop(['lower_bound_ip_address', 'upper_bound_ip_address'], axis=1)\n",
                "df_merged.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "m3n4o5p6",
            "metadata": {},
            "source": [
                "## 2. Feature Extraction\n",
                "Adding time-based features and transaction velocity."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "q7r8s9t0",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_merged['signup_time'] = pd.to_datetime(df_merged['signup_time'])\n",
                "df_merged['purchase_time'] = pd.to_datetime(df_merged['purchase_time'])\n",
                "\n",
                "# 2.1 Time since signup\n",
                "df_merged['time_since_signup'] = (df_merged['purchase_time'] - df_merged['signup_time']).dt.total_seconds()\n",
                "\n",
                "# 2.2 Time-of-day and Day-of-week\n",
                "df_merged['hour_of_day'] = df_merged['purchase_time'].dt.hour\n",
                "df_merged['day_of_week'] = df_merged['purchase_time'].dt.dayofweek\n",
                "\n",
                "# 2.3 Transaction frequency (Velocity)\n",
                "df_merged['user_id_count'] = df_merged.groupby('user_id')['user_id'].transform('count')\n",
                "df_merged['device_id_count'] = df_merged.groupby('device_id')['device_id'].transform('count')\n",
                "\n",
                "df_merged.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "u1v2w3x4",
            "metadata": {},
            "source": [
                "## 3. Save Processed Data\n",
                "Saving the output for the transformation step."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "y5z6a7b8",
            "metadata": {},
            "outputs": [],
            "source": [
                "os.makedirs('../data/processed', exist_ok=True)\n",
                "df_merged.to_csv('../data/processed/Fraud_Data_features.ipynb_output.csv', index=False)\n",
                "print(\"Feature engineering complete. Data saved.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "19a7d2ca",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
